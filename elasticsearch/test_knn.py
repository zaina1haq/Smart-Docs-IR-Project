# # from elasticsearch import Elasticsearch
# # from sentence_transformers import SentenceTransformer

# # es = Elasticsearch("http://localhost:9200")
# # model = SentenceTransformer("all-MiniLM-L6-v2")

# # query = "global"
# # vector = model.encode(query).tolist()

# # res = es.search(
# #     index="project-index",
# #     knn={
# #         "field": "content_embedding",
# #         "query_vector": vector,
# #         "k": 10,
# #         "num_candidates": 100
# #     }
# # )

# # print("Top semantic results:")
# # for hit in res["hits"]["hits"]:
# #     print(hit["_score"], hit["_source"].get("title"))
# from sentence_transformers import SentenceTransformer
# import json

# model = SentenceTransformer("all-MiniLM-L6-v2")

# query_vector = model.encode("economic slowdown in asia").tolist()

# print(json.dumps(query_vector))
from sentence_transformers import SentenceTransformer
import json

# Ù…ÙˆØ¯ÙŠÙ„ ÙŠØ¹Ø·ÙŠ 384 dims
model = SentenceTransformer("all-MiniLM-L6-v2")

# ====== Ø§Ù„Ù†Øµ Ø§Ù„Ù„ÙŠ Ø¨Ø¯Ùƒ ØªØ­ÙˆÙ„Ù‡ Vector ======
text = input("Ø§ÙƒØªØ¨ Ø§Ù„Ù†Øµ ØªØ¨Ø¹Ùƒ: ")

# ØªÙˆÙ„ÙŠØ¯ embedding
embedding = model.encode(text, normalize_embeddings=True)

# ØªØ­ÙˆÙŠÙ„Ù‡ Ù„Ù‚Ø§Ø¦Ù…Ø© Ø¹Ø´Ø§Ù† ÙŠØ·Ù„Ø¹ JSON
vector = embedding.tolist()

print("\nâœ… Vector Ø¬Ø§Ù‡Ø² (384 dims):\n")
print(json.dumps(vector, indent=2))

print(f"\nðŸ”¢ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯: {len(vector)}")
